# 11.28.7  Указывание на или стремление  к визуальному объекту.

Мы также можем попробовать сценарий `the arm_tracking.py`, введенный ранее в этой главе. Вместо поддельной цели, которую мы использовали в симуляторе, мы используем node `nearest_cloud.py`, который мы описали ранее, таким образом, что рука будет указывать или стремиться к ближайшему к камере объекту. 

Считая, что у вас все еще запущены launch-файлы и node MoveIt! для вашего робота, запустите node OpenNI для камеры глубины:

```bash
$ roslaunch rbx2_vision openni_node.launch
```

После запустите node `nearest_cloud.py`: 

```bash
$ roslaunch rbx2_vision nearest_cloud.launch 
```

Перед тем как запустить трекер руки, нам нужно запустить главный трекер \(head tracker\), чтобы робот поддерживал камеру глубины направленной на ближайший объект. Обратите внимание на то, что аргументу `sim` присваивается значение `false` в команде ниже: 

```bash
$ roslaunch rbx2_dynamixels head_tracker.launch sim:=false 
```

Наконец, запустите node `arm_tracker.py`: 

```bash
$ rosrun rbx2_arm_nav arm_tracker.py 
```

Если все пройдет гладко, робот должен периодически обновлять позицию своей руки таким образом, что захват более-менее тянется к ближайшему объекту перед камерой \(но удаленному по крайней мере на 0.5 метров\).

Оставляем читателю возможность улучшить сценарий `arm_tracker.py`, настроив ориентацию захвата таким образом, что он будет тянуться точно к цели вместо того, чтобы всегда оставаться в горизонтальном положении, как это происходит сейчас. Например, если цель находится выше уровня плеча, тянуться к цели будет не только вся рука, но и сам захват будет повернут наверх. 



