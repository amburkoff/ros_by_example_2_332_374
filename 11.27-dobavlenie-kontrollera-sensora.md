# 11.27  Добавление контроллера сенсора

До сих пор мы добавляли симулируемые объекты в планируемую сцену MoveIt! для тестирования избегания столкновений. MoveIt! также может использовать данные облака точек, полученные с камеры глубины для добавления информации о реальных препятствиях прямиком в сцену. Обратите внимание что это не то же самое, что и обнаружение определенных объектов для захвата, что мы рассмотрим позднее в этой главе и еще раз в следующих главах. MoveIt! просто строит сетку препятствий \(occupancy grid\) из данных о глубине, что позволяет планированию движений избегать столкновений с препятствиями.

MoveIt! Использует представление трехмерной окружающей среды в виде октодерева \(octree\). Как понятно из названия, каждая вершина октодерева имеет восемь дочерних вершин, которые могут быть использованы для представления восьми октантов, расположенных вокруг точки пространства, что является эффективным способом представления пространственной карты препятствий. MoveIt! на данный момент знает как использовать облака точек и карты глубины для создания представлений сцены планирования в виде октодерева. Настройка достаточно проста, как мы сейчас покажем для облаков точек.

Сначала добавим файл `sensors_rgbd.yaml` в директорию `config` конфигурационного пакета MoveIt! нашего робота. Он содержит следующие строки: 

```yaml
sensors:  
 - sensor_plugin: occupancy_map_monitor/PointCloudOctomapUpdater
 point_cloud_topic: 
/camera/depth_registered/points    max_range: 5.0  
frame_subsample: 1    point_subsample: 1    padding_offset: 0.1
padding_scale: 1.0    filtered_cloud_topic: filtered_cloud 
```



Файл определяет нашу коллекцию сенсоров с помощью использования плагинов сенсоров MoveIt!. В данном случае, мы определяем единственный плагин, который использует `PointCloudOctomapUpdater` для создания карты препятствий в виде октодерева. Этот плагин ожидает, что он будет подписан на топик с названием в параметре `point_cloud_topic`, в данном случае это `/camera/depth_registered/points`.  Далее мы указываем параметры для максимальной глубины \(в метрах\), которую мы хотим обрабатывать, скоростей замера видеопотока \(`frame_subsample`\)  и сетки облака точек \(`point_subsample`\).  Значение `padding_offset` \(в сантиметрах\) и `padding_scale` определяют какая часть буфера вокруг робота будет использована для создания self-filter. Результирующее облако точек за исключением частей робота публикуется в `filtered_cloud_topic`.

В дополнение к конфигурационному файлу `sensors_rgbd.yaml` нам так же нужен launch-файл, загружающий параметры. Для Pi Robot этот файл называется `pi_robot_moveit_sensor_manager.launch.xml` и он располагается в директории launch MoveIt! пакета Pi. Содержимое launch-файла следует далее: 

```markup
<launch> 
   <param name="octomap_frame" type="string" value="odom" /> 
   <param name="octomap_resolution" type="double" value="0.05" /> 
   <param name="max_range" type="double" value="1.5" /> 
   <rosparam command="load" file="$(find  
   pi_robot_moveit_config)/config/sensors_rgbd.yaml" /> 
</launch> 
```

где параметр `octomap_frame` задает систему координат, в которой данное представление будет храниться. Если вы работаете с мобильным роботом, этой системой отсчета следует быть фиксированной системе отсчета мира. Параметр `octomap_resolution` указывает разрешение, с которым представление поддерживается \(в метрах\).

Чтобы проверить как все работает, сначала запустите драйвер камеры OpenNI для вашего Kinect или Xtion Pro: 

```bash
$ roslaunch rbx2_vision openni_node.launch 
```

Далее запустите Pi Robot в симуляторе ArbotiX, если он еще не запущен: 

```bash
$ roslaunch rbx2_bringup pi_robot_with_gripper.launch sim:=true 
```

Теперь запустите MoveIt! среду для Pi Robot, которая включает в себя менеджера сенсоров, созданного выше: 

```bash
$ roslaunch pi_robot_moveit_config move_group.launch 
```

Наконец, запустите `RViz` с конфигурационным файлом `arm_nav.rviz`: 

```bash
$ rosrun rviz rviz -d `rospack find rbx2_arm_nav`/config/arm_nav.rviz 
```

Считая, что в поле зрения камеры есть объекты, изображение в `RViz` должно быть похоже на:	  

![](.gitbook/assets/4.png)

Если вы не видите кубов, представляющих сетку препятствий октокарты, проверьте что в разделе **Motion Planning** в настройках **Scene Geometry** стоит галочка в поле **Show Scene Geometry**. Кубы октокарты должны обновляться при движении объектов перед камерой.

Если вы используете настоящего робота, MoveIt! будет включать эту информацию о препятствиях при подсчете траекторий руки для избегания столкновений руки с обнаруженными объектами.

**ВНИМАНИЕ**: Если вы явно не используете данные октокарты вашим роботом, лучше будет отключить эту функцию, так как она потребляет большое количество энергии ЦП. Для отключения обработки сенсоров измените launch-файл сенсора, созданный нами выше \(для Pi Robot это файл `pi_robot_moveit_sensor_manager.launch.xml`\). Закомментируйте все строчки таким образом: 

```markup
<launch> <!-- 
   <param name="octomap_frame" type="string" value="odom" /> 
   <param name="octomap_resolution" type="double" value="0.05" /> 
   <param name="max_range" type="double" value="1.5" /> 
   <rosparam command="load" file="$(find  
pi_robot_moveit_config)/config/sensors_rgbd.yaml" /> --> 
</launch> 
```

Далее, остановите файл `move_group.launch`, если он запущен, потом удалите любые существующие параметры сенсоров перед тем как перезапустить файл `move_group.launch`:

```bash
$ rosparam delete /move_group/sensors 
$ roslaunch pi_robot_moveit_config move_group.launch 
```

Вам достаточно сделать это только один раз, так как `move_group.launch` больше не будет задавать параметры сенсоров, тем самым отключая обработку октокарты.

